# Details:

1. Embedding model is used to embedded the documents and add into vector store.
2. `Vector Search` is a database; 
    1. it's gonna be hosted locally on our own computer using something called [ChromaDB](https://docs.trychroma.com/docs/overview/getting-started).
    2. It allows quickly look up relevant information that we can pass to our model and model can return some contextual relevant replies.
2. `Context Length`: 
    1. Context length determines how much of your conversation your local LLM can remember and use to generate responses.


# Extras:

1. [tavily](https://app.tavily.com/home)
2. yfinance for retrieving stock data
3. quantmod for time series analysis
4. ggplot2 for visualization
5. dplyr for data manipulation
6. tidyr for tidying data


# GenAI

| id  | GenAI Name | Company   | Guide Links | Console Links |
| --- | :--------: | :-------: | :---------: | :-----------: |
| 1.  | Claude | Anthropic | [API Guide](https://docs.anthropic.com/en/docs/intro) | [Console](https://console.anthropic.com/dashboard) |
