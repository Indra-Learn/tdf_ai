# Details:

1. Embedding model is used to embedded the documents and add into vector store.
2. `Vector Search` is a database; 
    1. it's gonna be hosted locally on our own computer using something called [ChromaDB](https://docs.trychroma.com/docs/overview/getting-started).
    2. It allows quickly look up relevant information that we can pass to our model and model can return some contextual relevant replies.
2. `Context Length`: 
    1. Context length determines how much of your conversation your local LLM can remember and use to generate responses.


# Extras:

1. [tavily](https://app.tavily.com/home)
yfinance for retrieving stock data
quantmod for time series analysis
ggplot2 for visualization
dplyr for data manipulation
tidyr for tidying data